import pandas as pd
import torch
from core.interfaces import ILinkPredictor
from torch_geometric.loader import NeighborLoader, LinkNeighborLoader
from tqdm import tqdm
import torch.amp
from config.settings import NODES_DATA_PATH
class Predictor(ILinkPredictor):
    """
    L·ªõp d√πng ƒë·ªÉ t√≠nh to√°n v√† cache vector nh√∫ng (Z) c·ªßa t·∫•t c·∫£ c√°c node ('person'),
    sau ƒë√≥ th·ª±c hi·ªán t√¨m ki·∫øm node t∆∞∆°ng ƒë·ªìng (Link Prediction).
    """
    def __init__(self, model, data, device):
        self.model = model
        self.data = data
        self.device = device
        self.model.eval()
        self.model.to(device)
        self.embeddings = None
        self.connectivity_map = self._build_connectivity_map()
    @torch.no_grad()
    def _compute_all_embeddings(self, batch_size=128):
        """
        Ch·∫°y model 1 l·∫ßn ƒë·ªÉ l·∫•y vector c·ªßa T·∫§T C·∫¢ c√°c node.
        H√†m n√†y d√πng ƒë·ªÉ cache vector Z.
        """

        self.model.eval()
        loader = NeighborLoader(
            data = self.data,
            input_nodes = None,
            num_neighbors= [20,10],
            shuffle = False,
            num_workers = 0,
            batch_size= batch_size
        )

        temp_embs = {nt: [] for nt in self.data.node_types}

        with torch.no_grad():
            pbar = tqdm(loader, desc = "Encoding Nodes")
            for batch in pbar:
                batch = batch.to(self.device)

                with torch.amp.autocast('cuda'):
                    z_dict = self.model.encoder(batch.x_dict, batch.edge_index_dict)

                for nt, z in z_dict.items():
                    if nt in batch and batch[nt].batch_size is not None:
                        num_target = batch[nt].batch_size
                        temp_embs[nt].append(z[:num_target].cpu())

        for nt, embs in temp_embs.items():
            if embs:
                self.embeddings[nt] = torch.cat(embs, dim=0)

    def _get_score(self, src_id, dst_id, src_type, rel, dst_type):
        if src_type not in self.embeddings or dst_type not in self.embeddings:
            return 0.0

        try:
            vec_a = self.embeddings[src_type][src_id].to(self.device).unsqueeze(0)
            vec_b = self.embeddings[dst_type][dst_id].to(self.device).unsqueeze(0)
        except IndexError:
            return 0.0

        key = f"{src_type}__{rel}__{dst_type}"
        if key in self.model.decoders:
            logits = self.model.decoders[key](vec_a, vec_b)
            return torch.sigmoid(logits).item()
        else:
            return 0.0

    def scan_relationship(self, id_a, id_b, src_type = 'human', dst_type = 'human'):
        results = {}
        max_score = -1
        best_rel = None

        for et in self.data.edge_types:
            s, r, d = et
            if s == src_type and d == dst_type and not r.startswith('rev_'):
                score = self._get_score(id_a, id_b, s, r, d)
                results[r] = score

                if score > max_score:
                    max_score = score
                    best_rel = r
        return best_rel, max_score, results

    @torch.no_grad()
    def recommend_top_k_with_rel(self, src_id, rel_name, top_k=10, src_type='human'):
        """
        T√¨m Top-K node ƒë√≠ch c√≥ kh·∫£ nƒÉng li√™n k·∫øt cao nh·∫•t v·ªõi src_id theo quan h·ªá rel_name.
        """
        if not self.is_ready:
            raise RuntimeError("Ch∆∞a ch·∫°y .precompute_embeddings()!")
        for et in self.data.edge_types:
            s, rel, d = et
            if s == src_type and rel == rel_name:
                dst_type = d
                break
        # 1. X√°c ƒë·ªãnh Decoder chuy√™n gia
        key = f"{src_type}__{rel_name}__{dst_type}"
        if key not in self.model.decoders:
            raise ValueError(f"Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh cho quan h·ªá: {key}")

        decoder = self.model.decoders[key]

        # 2. Chu·∫©n b·ªã Vector ngu·ªìn (√îng A)
        try:
            # Shape: [1, Hidden_Dim]
            vec_src = self.embeddings[src_type][src_id].view(1, -1).to(self.device)
        except IndexError:
            return [], []  # ID kh√¥ng t·ªìn t·∫°i

        # 3. L·∫•y to√†n b·ªô Vector ƒë√≠ch (T·∫•t c·∫£ m·ªçi ng∆∞·ªùi)
        # Shape: [Num_Candidates, Hidden_Dim]
        # L∆∞u √Ω: candidates_emb ƒëang ·ªü CPU
        candidates_emb = self.embeddings[dst_type]
        num_candidates = candidates_emb.size(0)

        # 4. CH·∫†Y BATCH INFERENCE (ƒê·ªÉ kh√¥ng ch√°y VRAM)
        # V√¨ ch·ªâ l√† ph√©p nh√¢n ma tr·∫≠n ƒë∆°n gi·∫£n n√™n batch c√≥ th·ªÉ r·∫•t to
        eval_batch_size = 4096
        all_scores = []

        # Duy·ªát qua t·ª´ng c·ª•m ·ª©ng vi√™n
        for i in range(0, num_candidates, eval_batch_size):
            # C·∫Øt batch ·ª©ng vi√™n v√† ƒë∆∞a l√™n GPU
            batch_dst = candidates_emb[i: i + eval_batch_size].to(self.device)

            # M·ªü r·ªông vec_src ƒë·ªÉ kh·ªõp k√≠ch th∆∞·ªõc batch
            # [1, H] -> [Batch_Size, H]
            batch_src = vec_src.expand(batch_dst.size(0), -1)

            # T√≠nh ƒëi·ªÉm qua Decoder
            # D√πng AMP cho nhanh
            with torch.amp.autocast('cuda'):
                logits = decoder(batch_src, batch_dst)
                scores = torch.sigmoid(logits).view(-1)  # √âp v·ªÅ 1 chi·ªÅu

            # ƒê∆∞a v·ªÅ CPU ngay l·∫≠p t·ª©c ƒë·ªÉ ti·∫øt ki·ªám VRAM
            all_scores.append(scores.cpu())

        # 5. N·ªëi l·∫°i th√†nh 1 tensor ƒëi·ªÉm s·ªë kh·ªïng l·ªì
        final_scores = torch.cat(all_scores)

        # G√°n ƒëi·ªÉm -1.0 cho ch√≠nh b·∫£n th√¢n m√¨nh (ƒë·ªÉ kh√¥ng t·ª± g·ª£i √Ω m√¨nh)
        if src_type == dst_type:
            final_scores[src_id] = -1.0

        # 6. L·∫•y Top K (H√†m topk c·ªßa PyTorch si√™u nhanh)
        # values: ƒêi·ªÉm s·ªë, indices: ID c·ªßa ng∆∞·ªùi ƒë∆∞·ª£c g·ª£i √Ω
        values, indices = torch.topk(final_scores, k=top_k)

        return indices.numpy(), values.numpy()


    def predict_link_score(self):
        """
        T√≠nh to√°n ƒëi·ªÉm li√™n k·∫øt (link score) gi·ªØa hai vector v√† chuy·ªÉn th√†nh x√°c su·∫•t.
        """

    @torch.no_grad()
    def _build_connectivity_map(self):
        mapping = {}
        for src, rel, dst in self.data.edge_types:
            if rel.startswith('rev_'): continue

            if src not in mapping: mapping[src] = {}
            if dst not in mapping[src]: mapping[src][dst] = []

            mapping[src][dst].append(rel)
        return mapping

    @torch.no_grad()
    def recommend_top_k(self, src_id, top_k=10, src_type='human', dst_type=None):
        """
        H√†m g·ª£i √Ω ƒëa nƒÉng:
        - N·∫øu dst_type=None: T√¨m Top-K tr√™n TO√ÄN B·ªò h·ªá th·ªëng (Global).
        - N·∫øu dst_type='...': T√¨m Top-K ch·ªâ tr√™n lo·∫°i node ƒë√≥ (Specific).

        Returns:
            List[Dict]: Danh s√°ch k·∫øt qu·∫£ ƒë√£ sort.
            M·ªói item: {'id', 'type', 'relation', 'score'}
        """
        # 1. Ki·ªÉm tra ƒë·∫ßu v√†o
        if not hasattr(self, 'embeddings') or not self.embeddings:
            raise RuntimeError("Ch∆∞a c√≥ Embeddings. H√£y ch·∫°y precompute tr∆∞·ªõc.")

        if src_type not in self.embeddings: return []

        try:
            vec_src = self.embeddings[src_type][src_id].view(1, -1).to(self.device)
        except IndexError:
            return []  # ID ngu·ªìn kh√¥ng t·ªìn t·∫°i

        # 2. X√°c ƒë·ªãnh ph·∫°m vi t√¨m ki·∫øm (Target Groups)
        # target_groups d·∫°ng: {dst_type: [rel_name_1, rel_name_2]}
        target_groups = {}

        if dst_type is not None:
            # CASE A: T√¨m ki·∫øm c·ª• th·ªÉ (VD: ch·ªâ t√¨m 'human')
            if src_type in self.connectivity_map and dst_type in self.connectivity_map[src_type]:
                target_groups[dst_type] = self.connectivity_map[src_type][dst_type]
            else:
                return []  # Kh√¥ng c√≥ ƒë∆∞·ªùng n·ªëi gi·ªØa src v√† dst n√†y
        else:
            # CASE B: T√¨m ki·∫øm to√†n c·ª•c (Global)
            if src_type in self.connectivity_map:
                target_groups = self.connectivity_map[src_type]
            else:
                return []

        print(f"üåç ƒêang qu√©t li√™n k·∫øt t·ª´ '{src_type} #{src_id}' ƒë·∫øn {list(target_groups.keys())}...")

        global_candidates = []

        # 3. V√≤ng l·∫∑p ch√≠nh: Duy·ªát qua t·ª´ng lo·∫°i Node ƒê√≠ch
        for target_type, rel_names in target_groups.items():

            if target_type not in self.embeddings: continue

            candidates_emb = self.embeddings[target_type]  # CPU Tensor
            num_dst = candidates_emb.size(0)

            # Tensor l∆∞u Max Score cho m·ªói node ƒë√≠ch thu·ªôc lo·∫°i n√†y
            # (Kh·ªüi t·∫°o -1)
            type_max_scores = torch.full((num_dst,), -1.0, dtype=torch.float32)
            type_best_rels = [None] * num_dst  # L∆∞u t√™n quan h·ªá t·ªët nh·∫•t

            # 3.1. Max-Pooling qua c√°c quan h·ªá (VD: Friend vs Colleague)
            for rel_name in rel_names:
                key = f"{src_type}__{rel_name}__{target_type}"
                if key not in self.model.decoders: continue

                decoder = self.model.decoders[key]

                # Batch Inference
                batch_size = 4096
                for i in range(0, num_dst, batch_size):
                    batch_dst = candidates_emb[i: i + batch_size].to(self.device)
                    # Expand src ƒë·ªÉ kh·ªõp batch
                    batch_src = vec_src.expand(batch_dst.size(0), -1)

                    with torch.amp.autocast('cuda'):
                        logits = decoder(batch_src, batch_dst)
                        scores = torch.sigmoid(logits).view(-1).cpu()

                    # C·∫≠p nh·∫≠t Max Score th·ªß c√¥ng tr√™n CPU
                    # (Logic: N·∫øu score m·ªõi > score c≈© th√¨ c·∫≠p nh·∫≠t score v√† relation)
                    # D√πng slicing ƒë·ªÉ g√°n cho nhanh
                    current_slice = slice(i, i + len(scores))

                    # T·∫°o mask cho nh·ªØng ƒëi·ªÉm t·ªët h∆°n
                    mask = scores > type_max_scores[current_slice]

                    # Update Score
                    type_max_scores[current_slice] = torch.where(
                        mask, scores, type_max_scores[current_slice]
                    )

                    # Update Relation Name (C·∫ßn loop v√¨ ƒë√¢y l√† list string)
                    indices = torch.nonzero(mask).flatten() + i
                    for idx in indices:
                        type_best_rels[idx.item()] = rel_name

            # 3.2. X·ª≠ l√Ω Self-loop (Kh√¥ng g·ª£i √Ω ch√≠nh m√¨nh)
            if src_type == target_type:
                type_max_scores[src_id] = -1.0

            # 3.3. L·∫•y Top-K c·ª•c b·ªô (c·ªßa lo·∫°i node n√†y)
            # L·∫•y nhi·ªÅu h∆°n top_k m·ªôt ch√∫t ƒë·ªÉ khi g·ªôp Global kh√¥ng b·ªã thi·∫øu
            k_local = min(top_k, num_dst)
            vals, indices = torch.topk(type_max_scores, k=k_local)

            # ƒê∆∞a v√†o danh s√°ch t·ªïng
            for score, idx in zip(vals, indices):
                if score > 0.0:
                    idx = idx.item()
                    global_candidates.append({
                        'score': score.item(),
                        'id': idx,
                        'type': target_type,
                        'relation': type_best_rels[idx]
                    })

        # 4. S·∫Øp x·∫øp Global v√† l·∫•y Top-K cu·ªëi c√πng
        # Sort gi·∫£m d·∫ßn theo score
        global_candidates.sort(key=lambda x: x['score'], reverse=True)

        return global_candidates[:top_k]
