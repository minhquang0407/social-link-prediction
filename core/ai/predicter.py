import os
import torch.nn.functional as F

import torch
import torch.amp
from torch_geometric.loader import NeighborLoader
from tqdm import tqdm
from config.settings import PYG_DATA_PATH, PREDICT_DATA_PATH
from infrastructure.repositories import PyGDataRepository
from core.interfaces import ILinkPredictor


class Predictor(ILinkPredictor):
    def __init__(self, model, data=None, metadata=None, embeddings=None):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model = model

        # X·ª≠ l√Ω metadata
        if data is not None:
            self.data = data
            self.metadata = data.metadata()
        elif metadata is not None:
            self.metadata = metadata

        self.model.eval()
        self.model.to(self.device)

        if embeddings is not None:
            self.embeddings = embeddings
        else:
            if os.path.exists(str(PREDICT_DATA_PATH)):
                print(f"Found saved embeddings at {PREDICT_DATA_PATH}. Loading...")
                self.embeddings = torch.load(str(PREDICT_DATA_PATH), map_location='cpu')
            elif data is not None:
                print("No saved embeddings found. Computing fresh ones...")
                self.embeddings = self._compute_all_embeddings()
            else:
                raise ValueError("Predictor needs either 'embeddings', 'data', or a saved file to work!")

        # --- T√çNH DEGREE ƒê·ªÇ PH·∫†T HUBS ---
        if data is not None:
            self.node_degrees = self._compute_node_degrees(data)
        else:
            self.node_degrees = {}

        self.connectivity_map = self._build_connectivity_map()
        self.BIOLOGICAL_RELS = {
            'spouse', 'sibling', 'father', 'mother', 'child', 'student_of'
        }
        self.HUMAN_SRC_ONLY = {
            'educated_at', 'student_of'
        }

    def _compute_node_degrees(self, data):
        """T√≠nh b·∫≠c (degree) cho t·∫•t c·∫£ c√°c node ƒë·ªÉ d√πng cho Penalty"""
        print("Computing Node Degrees for Hub Penalty...")
        degrees_map = {}
        for node_type in data.node_types:
            num_nodes = data[node_type].num_nodes
            if num_nodes == 0: continue

            # Kh·ªüi t·∫°o vector 0
            d = torch.zeros(num_nodes, dtype=torch.float)

            # Duy·ªát qua c√°c c·∫°nh h∆∞·ªõng V√ÄO node_type n√†y
            for src, rel, dst in data.edge_types:
                if dst == node_type:
                    edge_index = data[(src, rel, dst)].edge_index
                    # ƒê·∫øm t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa dst_index
                    # bincount c·ª±c nhanh tr√™n CPU/GPU
                    dst_indices = edge_index[1].cpu()
                    d += torch.bincount(dst_indices, minlength=num_nodes).float()

            degrees_map[node_type] = d
        return degrees_map
    @torch.no_grad()
    def _compute_all_embeddings(self, batch_size=1024):
        """T√≠nh v√† tr·∫£ v·ªÅ Embeddings (Kh√¥ng l∆∞u attribute ƒë·ªÉ tr√°nh side-effect)"""
        repo = PyGDataRepository(PYG_DATA_PATH)
        data = repo.load_data()
        embeddings = {}
        self.model.eval()
        print(f"üöÄ Computing Embeddings on {self.device}...")

        for node_type in data.node_types:
            if data[node_type].num_nodes == 0: continue
            loader = NeighborLoader(
                data,
                num_neighbors=[50, 30],
                input_nodes=node_type,
                shuffle=False,
                num_workers=2,
                batch_size=batch_size
            )

            all_embs = []
            with torch.no_grad():
                for batch in tqdm(loader, desc=f"Enc {node_type}", leave=False):
                    batch = batch.to(self.device)
                    with torch.amp.autocast('cuda'):
                        z_dict = self.model.encoder(batch.x_dict, batch.edge_index_dict)

                    if node_type in z_dict:
                        bs = batch[node_type].batch_size
                        all_embs.append(z_dict[node_type][:bs].cpu())

            if all_embs:
                raw_emb = torch.cat(all_embs, dim=0)
                final_emb = F.normalize(raw_emb, p=2, dim=1)
                embeddings[node_type] = final_emb

        torch.save(embeddings, str(PREDICT_DATA_PATH))
        return embeddings

    @torch.no_grad()
    def _build_connectivity_map(self):
        # D√πng metadata (edge_types) ƒë∆∞·ª£c truy·ªÅn v√†o init thay v√¨ self.edge_types
        node_types, edge_types = self.metadata
        mapping = {}
        for src, rel, dst in edge_types:
            if src not in mapping: mapping[src] = {}
            if dst not in mapping[src]: mapping[src][dst] = []
            mapping[src][dst].append(rel)
        return mapping

    def scan_relationship(self, id_a, id_b, src_type, dst_type, mode='strict'):
        """
        Args:
            mode (str):
                - 'strict': Ch·ªâ check c√°c quan h·ªá c√≥ trong Metadata (Human-Org -> work_at).
                - 'loose': Check T·∫§T C·∫¢ quan h·ªá m√† model bi·∫øt (Human-Org -> th·ª≠ c·∫£ spouse, member_of...).
                           D√πng cho Zero-shot / Vay m∆∞·ª£n.
        """
        results = {}
        max_score = -1
        best_rel = None

        # 1. X√°c ƒë·ªãnh danh s√°ch quan h·ªá c·∫ßn ki·ªÉm tra
        candidate_rels = set()

        if mode == 'strict':
            # C√°ch c≈©: Ch·ªâ l·∫•y nh·ªØng g√¨ schema cho ph√©p
            candidate_rels = set(self.connectivity_map.get(src_type, {}).get(dst_type, []))
        else:
            # C√°ch m·ªõi (Zero-shot): L·∫•y TO√ÄN B·ªò c√°c quan h·ªá model ƒë√£ h·ªçc
            # Duy·ªát qua keys c·ªßa decoder ƒë·ªÉ tr√≠ch xu·∫•t t√™n quan h·ªá
            for key in self.model.decoders.keys():
                rel_name = key.strip('_')
                if '__' in key.strip('_'): rel_name = key.split('__')[1]
                candidate_rels.add(rel_name)

        # 2. Duy·ªát v√† D·ª± ƒëo√°n
        for rel in candidate_rels:
            if rel.startswith('rev_'): continue

            # --- [B·ªò L·ªåC NG·ªÆ NGHƒ®A - SEMANTIC FILTER] ---

            # Lu·∫≠t 1: Quan h·ªá Sinh h·ªçc (V·ª£ ch·ªìng, anh em...)
            if rel in self.BIOLOGICAL_RELS:
                if src_type != 'human' or dst_type != 'human':
                    continue

            # Lu·∫≠t 2: Quan h·ªá H√†nh vi con ng∆∞·ªùi (T√°c gi·∫£, ƒê·∫°o di·ªÖn...)
            if rel in self.HUMAN_SRC_ONLY:
                if src_type != 'human':
                    continue
            score = self._get_score_fast(id_a, id_b, src_type, rel, dst_type)

            if score > 0.001:
                results[rel] = score
                if score > max_score:
                    max_score = score
                    best_rel = rel

        return best_rel, max_score, results

    def _get_score_fast(self, src_id, dst_id, src_type, rel, dst_type):
        """Helper function t√≠nh ƒëi·ªÉm 1 c·∫°nh"""
        if rel.startswith('rev_'): rel = rel.replace('rev_', '')

        # Gi·∫£ s·ª≠ decoder l∆∞u theo key d·∫°ng "__rel__" nh∆∞ b·∫°n ƒë·ªãnh nghƒ©a
        key = f"__{rel}__"

        if key not in self.model.decoders: return 0.0

        try:
            vec_a = self.embeddings[src_type][src_id].to(self.device).view(1, -1)
            vec_b = self.embeddings[dst_type][dst_id].to(self.device).view(1, -1)
            logits = self.model.decoders[key](vec_a, vec_b)
            return torch.sigmoid(logits).item()
        except:
            return 0.0

    @torch.no_grad()
    def recommend_top_k(self, src_id, top_k=10, src_type='human', dst_type=None, rel_name=None):
        """
        H√ÄM G·ª¢I √ù TH·ªêNG NH·∫§T (UNIFIED RECOMMENDATION)
        X·ª≠ l√Ω c·∫£ 3 tr∆∞·ªùng h·ª£p:
        1. C√≥ rel_name -> T√¨m theo quan h·ªá c·ª• th·ªÉ.
        2. C√≥ dst_type -> T√¨m theo lo·∫°i ƒë√≠ch (Max-pool qua c√°c quan h·ªá).
        3. Kh√¥ng c√≥ g√¨ -> T√¨m to√†n c·ª•c (Global).
        """
        if src_type not in self.embeddings: return []

        try:
            vec_src = self.embeddings[src_type][src_id].view(1, -1).to(self.device)
        except IndexError:
            return []

        # 1. L√™n k·∫ø ho·∫°ch t√¨m ki·∫øm (Search Plan)
        search_plan = {}  # {dst_type: [rel1, rel2]}

        if rel_name:
            # Case 1: T√¨m theo quan h·ªá c·ª• th·ªÉ
            node_types, edge_types = self.metadata
            for s, r, d in edge_types:
                if s == src_type and r == rel_name:
                    if dst_type is None or dst_type == d:
                        if d not in search_plan: search_plan[d] = []
                        search_plan[d].append(r)
        elif dst_type:
            # Case 2: T√¨m theo lo·∫°i ƒë√≠ch
            rels = self.connectivity_map.get(src_type, {}).get(dst_type, [])
            if rels: search_plan[dst_type] = rels
        else:
            # Case 3: Global
            search_plan = self.connectivity_map.get(src_type, {})

        global_candidates = []
        eval_batch_size = 4096

        # 2. Th·ª±c thi
        for target_type, rels in search_plan.items():
            if target_type not in self.embeddings: continue

            candidates_emb = self.embeddings[target_type]
            num_candidates = candidates_emb.size(0)

            # Tensor l∆∞u Max Score cho m·ªói candidate c·ªßa lo·∫°i n√†y
            best_scores = torch.full((num_candidates,), -1.0, device='cpu')
            best_rels = [None] * num_candidates

            for r_name in rels:
                if r_name.startswith('rev_'): continue  # B·ªè qua c·∫°nh ng∆∞·ª£c n·∫øu mu·ªën

                key = f"__{r_name}__"  # Format key decoder
                if key not in self.model.decoders: continue
                decoder = self.model.decoders[key]

                # Batch Inference
                for i in range(0, num_candidates, eval_batch_size):
                    batch_dst = candidates_emb[i: i + eval_batch_size].to(self.device)
                    batch_src = vec_src.expand(batch_dst.size(0), -1)

                    with torch.amp.autocast('cuda'):
                        logits = decoder(batch_src, batch_dst)
                        scores = torch.sigmoid(logits).view(-1).cpu()
                        if hasattr(self, 'node_degrees') and target_type in self.node_degrees:
                            batch_indices = range(i, i + len(scores))
                            # L·∫•y degree an to√†n (tr√°nh l·ªói index out of bound)
                            if batch_indices[-1] < len(self.node_degrees[target_type]):
                                batch_degrees = self.node_degrees[target_type][batch_indices]
                                penalty = torch.log(batch_degrees + 1) + 1
                                scores = scores / penalty
                    # C·∫≠p nh·∫≠t Max Score
                    current_slice = slice(i, i + len(scores))
                    mask = scores > best_scores[current_slice]
                    best_scores[current_slice] = torch.where(mask, scores, best_scores[current_slice])

                    indices = torch.nonzero(mask).flatten() + i
                    for idx in indices:
                        best_rels[idx.item()] = r_name

            if src_type == target_type:
                best_scores[src_id] = -1.0

            k_local = min(top_k, num_candidates)
            vals, indices = torch.topk(best_scores, k=k_local)

            for val, idx in zip(vals, indices):
                if val > 0.0:
                    idx = idx.item()
                    global_candidates.append({
                        'id': idx,
                        'type': target_type,
                        'relation': best_rels[idx],
                        'score': val.item()
                    })

        global_candidates.sort(key=lambda x: x['score'], reverse=True)
        return global_candidates[:top_k]