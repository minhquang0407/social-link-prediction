import sys
import os
import itertools
import json
import torch
import torch.nn.functional as F
# import pandas as pd
import numpy as np
# from torch_geometric import edge_index
from tqdm import tqdm
from sklearn.metrics import roc_auc_score

# PyG Imports
from torch_geometric.loader import LinkNeighborLoader
from torch_geometric.nn import to_hetero
import torch_geometric.transforms as T
from torch_geometric.data import HeteroData

# Project Imports

from config.settings import (
    GRAPH_PATH, MODEL_PATH, PYG_DATA_PATH, MAPPING_PATH,
    CLEAN_DATA_PATH, TRAINING_HISTORY_PATH, BATCH_SIZE,
    INPUT_DIM, OUTPUT_DIM
)
from infrastructure.repositories.feature_repo import PyGDataRepository
from core.ai.gnn_architecture import GraphSAGE
# from core.ai.data_processor import GraphDataProcessor


# --- 1. CÃC HÃ€M TIá»†N ÃCH Xá»¬ LÃ DATA ---

def sanitize_hetero_data(data):
    """
    XÃ³a cÃ¡c loáº¡i cáº¡nh rá»—ng Ä‘á»ƒ trÃ¡nh lá»—i khi cháº¡y Loader.
    """
    print("ğŸ§¹ Äang dá»n dáº¹p cÃ¡c loáº¡i cáº¡nh rá»—ng...")
    # TODO 1: Duyá»‡t qua data.edge_types.
    edge_types_to_del = []
    for edge_type in data.edge_types:
    # Kiá»ƒm tra xem edge_index cÃ³ tá»“n táº¡i hoáº·c cÃ³ rá»—ng khÃ´ng.
        if 'edge_index' not in data[edge_type]:
            edge_types_to_del.append(edge_type)
            continue
        current_edge_index = data[edge_type].edge_index
        if current_edge_index is None or current_edge_index.numel() == 0 or current_edge_index.size(1) == 0:
            edge_types_to_del.append(edge_type)
    # Náº¿u rá»—ng thÃ¬ xÃ³a loáº¡i cáº¡nh Ä‘Ã³ khá»i data (dÃ¹ng del data[et]).
    if len(edge_types_to_del) > 0:
        for et in edge_types_to_del:
            print(f"   ÄÃ£ xÃ³a loáº¡i cáº¡nh rá»—ng: {et}")
            del data[et]
    else:
        print("   Dá»¯ liá»‡u sáº¡ch, khÃ´ng tÃ¬m tháº¥y loáº¡i cáº¡nh rá»—ng.")
    return data


def get_unified_edge_index(data, src_node_type='person', dst_node_type='person'):
    """
    Gá»™p táº¥t cáº£ cÃ¡c loáº¡i cáº¡nh ná»‘i giá»¯a Person-Person láº¡i thÃ nh má»™t 'SiÃªu cáº¡nh'
    Ä‘á»ƒ lÃ m nhÃ£n huáº¥n luyá»‡n (Supervision Target).
    """
    print(f"ğŸ”— Äang tá»•ng há»£p cÃ¡c cáº¡nh ná»‘i giá»¯a '{src_node_type}' vÃ  '{dst_node_type}':")
    edge_indices_list = []
    # TODO 2: Duyá»‡t qua data.edge_types.
    for edge_type in data.edge_types:
        src, rel, dst = edge_type
    # 1. Chá»‰ láº¥y cáº¡nh ná»‘i src_node_type vÃ  dst_node_type.
        if src == src_node_type and dst == dst_node_type:
            # 2. Bá» qua cÃ¡c cáº¡nh nghá»‹ch Ä‘áº£o (báº¯t Ä‘áº§u báº±ng 'rev_') Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p.
            if rel.startswith('rev_'):
                continue
            # 3. Thu tháº­p edge_index vÃ o má»™t list.
            edge_indices_list.append(data[edge_type].edge_index)
    if not edge_indices_list:
        print("   âš ï¸ KhÃ´ng tÃ¬m tháº¥y cáº¡nh nÃ o phÃ¹ há»£p.")
        return torch.empty(2, 0, dtype=torch.long)
    # TODO 3: Ná»‘i (Concat) táº¥t cáº£ edge_index láº¡i theo chiá»u ngang (dim=1).
    super_edge_index = torch.cat(edge_indices_list, dim=1)
    # TODO 4: Lá»c bá» cÃ¡c cáº¡nh trÃ¹ng láº·p (dÃ¹ng torch.unique).
    super_edge_index = torch.unique(super_edge_index, dim=1)
    # Return vá» super_edge_index
    return super_edge_index # Placeholder


def get_or_prepare_data():
    """Táº£i vÃ  chuáº©n bá»‹ dá»¯ liá»‡u (Undirected + Sanitize)."""
    feature_repo = PyGDataRepository(PYG_DATA_PATH, MAPPING_PATH)
    data, mapping = feature_repo.load_data()

    if data is None:
        print("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u PyG. Vui lÃ²ng cháº¡y ETL trÆ°á»›c!")
        return None

    # TODO 5: Thá»±c hiá»‡n quy trÃ¬nh lÃ m sáº¡ch vÃ  chuyá»ƒn Ä‘á»•i Ä‘á»“ thá»‹:
    # 1. Gá»i sanitize_hetero_data láº§n 1.
    data = sanitize_hetero_data(data)
    # 2. Chuyá»ƒn Ä‘á»“ thá»‹ sang vÃ´ hÆ°á»›ng (dÃ¹ng T.ToUndirected()).
    transform = T.ToUndirected()
    data = transform(data)
    # 3. Gá»i sanitize_hetero_data láº§n 2 (Ä‘á»ƒ dá»n rÃ¡c do ToUndirected sinh ra).
    data = sanitize_hetero_data(data)

    return data


# --- 2. CÃC HÃ€M TRAIN & EVAL ---

def train_epoch(model, loader, optimizer, device, target_edge_type):
    """Cháº¡y 1 epoch huáº¥n luyá»‡n."""
    model.train()
    total_loss = 0
    total_examples = 0

    for batch in tqdm(loader, desc="Training", leave=False):
        batch = batch.to(device)
        optimizer.zero_grad()
        # TODO 6: Quan trá»ng - Ã‰p kiá»ƒu dá»¯ liá»‡u (Data Type Casting)
        # Kiá»ƒm tra batch.x_dict, náº¿u lÃ  Float16 thÃ¬ Ã©p vá» Float32 Ä‘á»ƒ trÃ¡nh lá»—i matmul.
        for node_type in batch.x_dict:
            batch.x_dict[node_type] = batch.x_dict[node_type].float()

        # TODO 7: Forward Pass
        # 1. ÄÆ°a dá»¯ liá»‡u qua model Ä‘á»ƒ láº¥y z_dict (embedding).
        z_dict = model(batch.x_dict, batch.edge_index_dict)
        # 2. Láº¥y edge_label_index vÃ  edge_label tá»« batch[target_edge_type].
        edge_label_index = batch[target_edge_type].edge_label_index
        edge_label = batch[target_edge_type].edge_label
        
        # TODO 8: Decode (TÃ­nh Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng)
        src_type, _, dst_type = target_edge_type
        # Láº¥y embedding cá»§a node nguá»“n vÃ  node Ä‘Ã­ch, thá»±c hiá»‡n Dot Product.
        z_src = z_dict[src_type][edge_label_index[0]]
        z_dst = z_dict[dst_type][edge_label_index[1]]
        scores = (z_src * z_dst).sum(dim=-1)

        # TODO 9: TÃ­nh Loss vÃ  Backprop
        # DÃ¹ng binary_cross_entropy_with_logits.
        loss = F.binary_cross_entropy_with_logits(scores, edge_label)
        # Gá»i backward() vÃ  optimizer.step().
        loss.backward()
        optimizer.step()
        # Cáº­p nháº­t total_loss
        total_loss += loss.item() * edge_label.size(0)
        total_examples += edge_label.size(0)

    return total_loss / (total_examples + 1e-9)



@torch.no_grad()
def evaluate(model, loader, device, target_edge_type):
    """ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh."""
    model.eval()
    preds = []
    ground_truths = []

    for batch in tqdm(loader, desc="Evaluating", leave=False):
        batch = batch.to(device)

        # TODO 10: Ã‰p kiá»ƒu dá»¯ liá»‡u vá» Float32 (tÆ°Æ¡ng tá»± train_epoch).
        for node_type in batch.x_dict:
            batch.x_dict[node_type] = batch.x_dict[node_type].float()
        # TODO 11: Forward Pass vÃ  Decode
        # TÆ°Æ¡ng tá»± train_epoch, nhÆ°ng KHÃ”NG tÃ­nh loss, KHÃ”NG backprop.
        z_dict = model(batch.x_dict, batch.edge_index_dict)
        edge_label_index = batch[target_edge_type].edge_label_index
        edge_label = batch[target_edge_type].edge_label

        src_type, _, dst_type = target_edge_type
        z_src = z_dict[src_type][edge_label_index[0]]
        z_dst = z_dict[dst_type][edge_label_index[1]]

        # LÆ°u Ã½: Káº¿t quáº£ output cáº§n qua hÃ m .sigmoid() Ä‘á»ƒ vá» xÃ¡c suáº¥t [0, 1].
        scores = (z_src * z_dst).sum(dim=-1).sigmoid()

        # Append káº¿t quáº£ vÃ o preds vÃ  ground_truths
        preds.append(scores.cpu().numpy())
        ground_truths.append(edge_label.cpu().numpy())

    if len(preds) == 0:
        return 0.0

    # TODO 12: TÃ­nh ROC AUC Score dÃ¹ng sklearn
    y_pred = np.concatenate(preds)
    y_true = np.concatenate(ground_truths)

    return roc_auc_score(y_true, y_pred)


# --- 3. CHIáº¾N LÆ¯á»¢C CHáº Y ---

def train_one_config(data, config, device, final_mode=False):
    """Huáº¥n luyá»‡n vá»›i 1 cáº¥u hÃ¬nh cá»¥ thá»ƒ."""
    hidden_dim = config['hidden_dim']
    lr = config['lr']
    epochs = config['epochs']

    # --- CHUáº¨N Bá»Š Dá»® LIá»†U ---
    # TODO 13: Gá»i hÃ m get_unified_edge_index Ä‘á»ƒ táº¡o 'SiÃªu cáº¡nh' cho viá»‡c training.
    super_edge_index = get_unified_edge_index(data, src_node_type='person', dst_node_type='person')
    target_edge_type = ('person', 'super_link', 'person')
    # TODO 14: Chia dá»¯ liá»‡u (Split Train/Val)
    num_edges = super_edge_index.size(1)
    perm = torch.randperm(num_edges)
    # Náº¿u final_mode=True: DÃ¹ng toÃ n bá»™ siÃªu cáº¡nh Ä‘á»ƒ train.
    if final_mode:
        train_edge_index = super_edge_index
        val_loader = None
    # Náº¿u final_mode=False: Chia 80% train, 20% val (dÃ¹ng torch.randperm).
    else:
        num_train = int(0.8 * num_edges)
        train_index = perm[:num_train]
        val_index = perm[num_train:]
        train_edge_index = super_edge_index[:, train_index]
        val_edge_index = super_edge_index[:, val_index]

    # TODO 15: Khá»Ÿi táº¡o LinkNeighborLoader
        # - Val Loader (náº¿u cÃ³): shuffle=False, neg_sampling_ratio=1.0
        val_loader = LinkNeighborLoader(
            data,
            num_neighbors=[10, 5],  # Sample Ã­t hÆ¡n cho nhanh
            edge_label_index=(target_edge_type, val_edge_index),
            edge_label=torch.ones(val_edge_index.size(1), device=data['person'].x.device),
            batch_size=BATCH_SIZE,
            shuffle=False,
            neg_sampling_ratio=1.0  # Tá»‰ lá»‡ 1:1 cho táº­p val
        )
    # - Train Loader: shuffle=True, neg_sampling_ratio=1.0
    train_loader = LinkNeighborLoader(
        data,
        num_neighbors=[20, 10],
        edge_label_index=(target_edge_type, train_edge_index),
        edge_label=torch.ones(train_edge_index.size(1), device=data['person'].x.device),
        batch_size=BATCH_SIZE,
        shuffle=True,
        neg_sampling_ratio=1.0  # Tá»‰ lá»‡ 1:1 cho táº­p train
    )

    # LÆ°u Ã½: edge_label_index trá» vÃ o pháº§n data Ä‘Ã£ split á»Ÿ trÃªn.

    # --- KHá»I Táº O MODEL ---
    # TODO 16: Khá»Ÿi táº¡o GraphSAGE vÃ  convert sang Hetero (to_hetero).
    # Input dim láº¥y tá»« data['person'].x.shape[1].
    # input_dim = data['person'].x.shape[1] if 'person' in data else INPUT_DIM
    base_model = GraphSAGE(
        hidden_channels = hidden_dim,
        out_channels = OUTPUT_DIM
    )
    model = to_hetero(base_model, data.metadata(), aggr='sum').to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    history = {"epoch": [], "loss": [], "val_auc": []}
    best_val_auc = 0
    best_model_state = None

    print(f"\nğŸš€ Báº¯t Ä‘áº§u train (Hidden={hidden_dim}, LR={lr})...")

    # --- TRAINING LOOP ---
    for epoch in range(1, epochs + 1):
        # TODO 17: Gá»i train_epoch
        loss = train_epoch(model, train_loader, optimizer, device, target_edge_type)
        
        # Log history
        history["epoch"].append(epoch)
        history["loss"].append(float(loss))

        log_msg = f"Epoch {epoch:03d} | Loss: {loss:.4f}"

        # TODO 18: Náº¿u cÃ³ val_loader, gá»i evaluate
        # Cáº­p nháº­t best_val_auc vÃ  best_model_state náº¿u káº¿t quáº£ tá»‘t hÆ¡n.
        if val_loader is not None:
            val_auc = evaluate(model, val_loader, device, target_edge_type)
            history["val_auc"].append(float(val_auc))
            log_msg += f" | Val AUC: {val_auc:.4f}"

            if val_auc > best_val_auc:
                best_val_auc = val_auc
                best_model_state = model.state_dict().copy()
        else:
            # Final mode: LuÃ´n cáº­p nháº­t model má»›i nháº¥t
            best_model_state = model.state_dict().copy()

        print(log_msg)

    # Xá»­ lÃ½ final mode
    if final_mode:
        print(f"ğŸ’¾ Äang lÆ°u lá»‹ch sá»­ huáº¥n luyá»‡n vÃ o {TRAINING_HISTORY_PATH}...")
        try:
            with open(TRAINING_HISTORY_PATH, 'w') as f:
                json.dump(history, f, indent=4)
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ lÆ°u lá»‹ch sá»­: {e}")
        best_val_auc = 1.0  # Placeholder cho final mode

    return best_val_auc, best_model_state


def run_grid_search():
    """Cháº¡y Grid Search vÃ  Final Training."""
    data = get_or_prepare_data()
    if data is None: return

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ Running on: {device}")

    # Grid Search Configs
    param_grid = {
        'hidden_dim': [64, 128],
        'lr': [0.01],
        'epochs': [10]
    }
    
    # Táº¡o combinations tá»« param_grid
    keys, values = zip(*param_grid.items())
    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]

    best_auc = 0
    best_params = None

    # TODO 19: Grid Search Loop
    # Duyá»‡t qua cÃ¡c config trong combinations.
    for config in combinations:
    # Gá»i train_one_config vá»›i final_mode=False.
        print(f"\nğŸ§ª Testing config: {config}")
        auc, _ = train_one_config(data, config, device, final_mode=False)
    # So sÃ¡nh vÃ  lÆ°u láº¡i config tá»‘t nháº¥t (best_auc).
        if auc > best_auc:
            best_auc = auc
            best_params = config
    print(f"\nğŸ¥‡ Best Params: {best_params} (AUC: {best_auc:.4f})")
    
    # TODO 20: Final Training
    # Cáº­p nháº­t epochs lÃªn cao hÆ¡n (vÃ­ dá»¥ 50).
    print("\nğŸ‹ï¸ Báº¯t Ä‘áº§u Final Training (50 Epochs) vá»›i tham sá»‘ tá»‘t nháº¥t...")
    if best_params is None:
        best_params = combinations[0]  # Fallback
    final_config = best_params.copy()
    final_config['epochs'] = 50  # TÄƒng epoch

    # Gá»i train_one_config vá»›i final_mode=True dÃ¹ng best_params.
    _, final_state = train_one_config(data, final_config, device, final_mode=True)
    # LÆ°u model (torch.save) vÃ o MODEL_PATH.
    print(f"ğŸ’¾ Äang lÆ°u mÃ´ hÃ¬nh vÃ o {MODEL_PATH}...")
    try:
        # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
        os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
        torch.save(final_state, MODEL_PATH)
        print("ğŸ‰ HoÃ n táº¥t quy trÃ¬nh huáº¥n luyá»‡n!")
    except Exception as e:
        print(f"âŒ Lá»—i khi lÆ°u model: {e}")

if __name__ == "__main__":
    run_grid_search()
